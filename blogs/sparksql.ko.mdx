---
id: 1251
date: 2023-10-12
tags: ["spark"]
title: Spark Sql
slug: sparksql
seq: 4
type: interest
language: kr
featureImage: /images/interest/spark-sql-big.png
thumb: /images/interest/spark-sql.png
github:
demo:
videoSourceURL:
videoTitle:
excerpt: spark rdd를 추상화하여 dataframe과 dataset, sql로 사용 편의성을 높혔다.
---

### Contents

### sql view 생성

    <SearchAntTab
          arr={[
            {
              id: "spark_test",
              label: "test",
              content: <SearchShow
                id="dvela3"
                script="ssh yknam@namubuntu curl GET http://namubuntu:9200/nginx-2023.10.25/_mapping"
                comment={<Cardd >
                  <div className="text-white">
                    <h1>Href Attribute Example</h1>
                    <p>
                      <a href="https://www.freecodecamp.org/contribute/">The freeCodeCamp Contribution Page</a> shows you how and where you can contribute to freeCodeCamp's community and growth.
                    </p>
                  </div>
                </Cardd>}
              />
            },
            {
              id: "spark_mysql",
              label: "mysql",
              content: [
                {
                  id: "pyspark",
                  label: "pyspark",
                  script: "cat /home/yknam/pythonfiles/pyspark/sparkSqlMysql.py",
                  content: (
                    <SearchShow
                      script="cat /home/yknam/pythonfiles/pyspark/sparkSqlMysql.py"
                      script1="/home/yknam/pythonfiles/pyspark/sparkSqlMysql.py"
                    ></SearchShow>
                  ),
                }, {
                  id: "spark_scala",
                  label: "scala",
                  script: "ssh nam cat /home/yknam/sandbox/filebeat/conf/filebeat1.yml",
                  content:
                    (
                      <SearchShow
                        id="file6"
                        script="ssh nam cat /home/yknam/sandbox/filebeat/conf/filebeat1.yml"
                        script1="curl get http://imcmaster.iptime.org:9200/filebeat*/_search"
                        type1="json"
                        comment1={
                          <>
                            <Chipp>filebeat → elasticsearch</Chipp>
                            <Codee>

                              curl get http://localhost:9200/filebeat*/_search
                            </Codee>
                          </>
                        }
                      ></SearchShow>
                    ),
                }
              ]
            },

          ]}
        />

### csv data

    <SearchShow
          id="spark_dvela3"
          script="cat /home/yknam/pythonfiles/pyspark/sparkSqlCsv.py"
          script1="/home/yknam/pythonfiles/pyspark/sparkSqlCsv.py"
        />

### data sources

### hive

### mysql jdbc

>

    <SearchAntTab
          arr={[
            {
              id: "spark_read",
              label: "read",
              content: [
                {
                  id: "pyspark",
                  label: "pyspark",
                  script: "cat /home/yknam/pythonfiles/pyspark/sparkSqlMysql.py",
                  content: (
                    <SearchShow
                      script="cat /home/yknam/pythonfiles/pyspark/sparkSqlMysql.py"
                      script1="/home/yknam/pythonfiles/pyspark/sparkSqlMysql.py"
                      compare="pyspark"
                    ></SearchShow>
                  ),
                }, {
                  id: "spark_scala",
                  label: "scala",
                  script: "cat /home/yknam/scalaproject/scala_spark/src/main/scala/sparkSqlMysql.scala",
                  content:
                    (
                      <SearchShow
                        script="cat /home/yknam/scalaproject/scala_spark/src/main/scala/sparkSqlMysql.scala"
                        script1="spark-submit --master local[1] --class com.yknam.SparkSessionTest /home/yknam/scalaproject/scala_spark/target/scala-2.12/scala_spark_2.12-0.1.0-SNAPSHOT.jar"
                        compare="scala"
                      ></SearchShow>
                    ),
                }
              ]
            },
            {
              id: "spark_write",
              label: "write",
              content: [
                {
                  id: "spark_pyspark",
                  label: "pyspark",
                  script: "cat /home/yknam/pythonfiles/pyspark/sparkSqlMysqlWrite.py",
                  content: (
                    <SearchShow
                      script="cat /home/yknam/pythonfiles/pyspark/sparkSqlMysqlWrite.py"
                      script1="/home/yknam/pythonfiles/pyspark/sparkSqlMysqlWrite.py"
                      compare="pyspark"
                    ></SearchShow>
                  ),
                }, {
                  id: "spark_scala",
                  label: "scala",
                  script: "cat /home/yknam/scalaproject/scala_spark/src/main/scala/sparkSqlMysqlWrite.scala",
                  content:
                    (
                      <SearchShow
                        id="spark_scala_write"
                        script="cat /home/yknam/scalaproject/scala_spark/src/main/scala/sparkSqlMysqlWrite.scala"
                        script1="spark-submit --master local[1] --class com.yknam.SparkSessionTest /home/yknam/scalaproject/scala_spark/target/scala-2.12/scala_spark_2.12-0.1.0-SNAPSHOT.jar"
                        compare="scala"
                      ></SearchShow>
                    ),
                }
              ]
            },
          ]}
        />

    <Alertt
          title="💡 scala 실행"
          shortmsg={
            <h4>
              $SPARK_HOME/bin/spark-submit --class com.yknam.HelloWorld \
              /home/yknam/scalaproject/scala_spark/target/scala-2.12/scala_spark_2.12-0.1.0-SNAPSHOT.jar
            </h4>
          }
          longmsg={
            <>
              <h4>
                $SPARK_HOME/bin/spark-submit --class com.yknam.HelloWorld \
                /home/yknam/scalaproject/scala_spark/target/scala-2.12/scala_spark_2.12-0.1.0-SNAPSHOT.jar
              </h4>
              <ul>
                <p>1. spark-submit</p>
                <p>2. --class</p>
                <p>3. 패키지명.클래스명: com.yknam+ .HelloWorld</p>
                <p>
                  4. jar파일:
                  디렉토리(/home/yknam/scalaproject/scala_spark/target/scala-2.12/)+jar파일(scala_spark_2.12-0.1.0-SNAPSHOT.jar)
                </p>
              </ul>
              <h4>intellij에서 sbt build</h4>
              <p>컴파일할 폴더root에서 </p>
              <code>sbt clean build</code>
            </>
          }
        />
### dataset

> Hdfs 파일 리스트 조회

```python
from pyspark import SparkContext
from pyspark.sql import SparkSession

# sc = SparkContext(appName="sparkRdd")
spark = SparkSession.builder.appName(
    "sparkRdd").master("local[2]").getOrCreate()

# From Mysql table
df_mysql = spark.read.format("jdbc")
   .option("url", "jdbc:mysql://winubuntu:3306/project")
   .option("driver", "com.mysql.jdbc.Driver")
   .option("dbtable", "tablename")
   .option("user", "user")
   .option("password", "password")
   .load()
```

