---
id: 1251
date: 2023-10-12
tags: ["spark", "rdd", "sparkcore"]
title: Spark core
slug: sparkcore
seq: 4
type: interest
language: kr
featureImage: /images/interest/spark-big.png
thumb: /images/interest/spark.png
github:
demo:
videoSourceURL:
videoTitle:
excerpt: 데이터 파이프라인을 관리하는 툴로 정교한 스케쥴기반의 프로세스를 통제한다.
---

## spark rdd 기본

<SearchShow
  script="cat /home/yknam/pythonfiles/pyspark/sparkRdd1.py"
  script1="/home/yknam/pythonfiles/pyspark/sparkRdd1.py"
  port="7878"
/>
<div
  style={{
    marginTop: "-25px",
    backgroundColor: "#e2e2e2",
    padding: "0 10px 20px 10px",
  }}
>
  <details>
    <summary>something to hide</summary>
    ### hide details
    <SearchLabel
      script="/home/yknam/pythonfiles/pyspark/sparkRdd1.py"
      port="7878"
    />
  </details>
</div>

#### master설정

<div style={{ float: "right", marginLeft: "20px" }}>
  <img src="/images/interest/spark-master.png" width="300" alt="master" />
</div>

- **driver only**: worker없이 driver로만 실행됨 local (코어갯수지정)
- **standalone**: spark://localhost:7077로 지정. spark만으로 클러스터를 구성
- **multinode**: resource manager와 node manager를 yarn에 의존한다.
  <div style={{ clear: "both" }} />

#### broadcast vs accumulator

<div style={{ float: "right", marginLeft: "20px" }}>
  <img
    src="/images/interest/sparkcore-broadcast.png"
    width="300"
    alt="broadcastjoin"
  />
</div>

> 브로드캐스트변수는 파일 사이즈가 작을 경우 driver에서 각 work로 복사하여 사용한다.
> accumulator변수는 각worker에서 공유되는 변수로 변수값이 합쳐진다.

<div style={{ clear: "both" }} />
<SearchShow
  script="cat /home/yknam/pythonfiles/pyspark/sparkRddToDF.py"
  port="7878"
/>
#### map side join vs shuffle join
<div style={{ float: "right", marginLeft: "20px" }}>
  <img
    src="/images/interest/sparkcore-shuffle.png"
    width="300"
    alt="shufflejoin"
  />
</div>

> worker 내에서 조인이 발생되는 경우와 worker간에 shuffle이 발생하여
> 조인이 일어나는 경우

<div style={{ clear: "both" }} />
